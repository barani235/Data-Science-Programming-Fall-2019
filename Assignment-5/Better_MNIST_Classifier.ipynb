{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\"> MNIST Classifier using TensorFlow</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The following changes are made to the previous classifier:</h3>\n",
    "<ul>\n",
    "    <li><h5>A convolutional layer is added</h5></li>\n",
    "    <li><h5>A max pooling layer is added</h5></li>\n",
    "    <li><h5>The batch size is reduced to 100</h5></li>\n",
    "    <li><h5>The number of epochs is increased to 10</h5></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Import the libraries TensorFlow and NumPy </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow version used here is 1.13.2\n",
    "<br>Use <b>pip install tensorflow=1.13.2</b> to install tensorflow 1.13.2 \n",
    "<br>This will replace the current version of tensorflow, if installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Construct the CNN classifier by building the graph using TensorFlow </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # Reset any existing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "\n",
    "# Rehsape the input to the format('all_rows', 28, 28, 1)\n",
    "X_reshaped = tf.reshape(X, shape=[-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-8f22816ba015>:5: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# The below convolutional layer with 32 filters, a kernel size of 3, a stride of 2, SAME padding and with the \n",
    "# ReLU activation function processes the input and produces an output of the shape (-1, 28, 28, 32)\n",
    "\n",
    "convolutional_layer_1 = tf.layers.conv2d(X_reshaped, filters=32, kernel_size=3,strides=1, \n",
    "                                         padding=\"SAME\", activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below max pooling layer with a kernel size of 2, a stride of 2, VALID padding processes the input \n",
    "# and produces an output of the shape (-1, 14, 14, 32)\n",
    "\n",
    "pooling_layer_1 = tf.nn.max_pool(convolutional_layer_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below convolutional layer with 64 filters, a kernel size of 3, a stride of 2, SAME padding and with the \n",
    "# ReLU activation function processes the input and produces an output of shape (-1, 7, 7, 64)\n",
    "\n",
    "convolutional_layer_2 = tf.layers.conv2d(pooling_layer_1, filters=64, kernel_size=3,strides=2, \n",
    "                                         padding=\"SAME\", activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below max pooling layer with a kernel size of 2, a stride of 2, VALID padding processes the input \n",
    "# and produces an output of the shape (-1, 4, 4, 64)\n",
    "\n",
    "pooling_layer_2 = tf.nn.max_pool(convolutional_layer_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pooling layer output is flattened to the shape (-1, 576)\n",
    "\n",
    "flattened_pooling_layer = tf.reshape(pooling_layer_2, shape=[-1, 64 * 3 * 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-d7d1a3537b05>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "# The dense layer will produce an output of the shape (-1, 64) after passing through the relu activation function\n",
    "\n",
    "fully_connected_layer = tf.layers.dense(flattened_pooling_layer, 64, activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fully connected output layer layer with linear activation function produces an output of the shape (-1,10)\n",
    "\n",
    "logits = tf.layers.dense(fully_connected_layer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability is calculated as a function of softmax\n",
    "\n",
    "Y_probability = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cross entropy is calculated to measure the loss\n",
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss function calculates the loss in the form of reduced mean\n",
    "\n",
    "loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer is used to reduce the loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The In Top K function returns if the predicted probability of a target class is in the first 'K' predictions\n",
    "# In the case below, it checks if the target class is predicted with highest probability\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below function is used to calculate the accuracy\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model parameters\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Load MNIST data from the Library</h6>\n",
    "<br><ul><li>The data is already split into training and test sets</li>\n",
    "<li>Re-shape the data to the format (28,28)</li>\n",
    "<li>Fix the pixel values to range from float 0 to 1</li>\n",
    "<li>Split the test set set further to create a validation set</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Define the number epochs, batch size and a function to create batches of samples</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10 \n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create batches of training data to be fed to the classifier\n",
    "\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Train the model and evaluate the training and validation accuracy</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # Create an initializer object\n",
    "sess = tf.Session() # Create a tensorflow session\n",
    "sess.run(init) # Initialize the graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Last batch accuracy: 0.97 Validation accuracy: 0.9672\n",
      "Epoch: 2 Last batch accuracy: 0.99 Validation accuracy: 0.9764\n",
      "Epoch: 3 Last batch accuracy: 1.0 Validation accuracy: 0.9798\n",
      "Epoch: 4 Last batch accuracy: 0.97 Validation accuracy: 0.9828\n",
      "Epoch: 5 Last batch accuracy: 0.99 Validation accuracy: 0.9862\n",
      "Epoch: 6 Last batch accuracy: 0.98 Validation accuracy: 0.9836\n",
      "Epoch: 7 Last batch accuracy: 1.0 Validation accuracy: 0.988\n",
      "Epoch: 8 Last batch accuracy: 1.0 Validation accuracy: 0.989\n",
      "Epoch: 9 Last batch accuracy: 0.99 Validation accuracy: 0.987\n",
      "Epoch: 10 Last batch accuracy: 1.0 Validation accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    acc_batch = sess.run(accuracy, feed_dict={X: X_batch, y: y_batch})\n",
    "    acc_valid = sess.run(accuracy, feed_dict={X: X_valid, y: y_valid})\n",
    "    print(\"Epoch:\", epoch+1 , \"Last batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "    save_path = saver.save(sess, \"./my_mnist_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Use the trained model for prediction</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection=np.random.choice(10000,size=10)\n",
    "X_pred = X_test[selection]\n",
    "y_actual = y_test[selection]\n",
    "y_probability_pred = sess.run(Y_probability, feed_dict = {X: X_pred})\n",
    "y_pred=[]\n",
    "for val in y_probability_pred:\n",
    "    y_pred.append(np.argmax(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Predicted\n",
      "5 \t 5\n",
      "3 \t 3\n",
      "5 \t 5\n",
      "2 \t 2\n",
      "3 \t 3\n",
      "1 \t 1\n",
      "2 \t 2\n",
      "7 \t 7\n",
      "0 \t 0\n",
      "2 \t 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Predicted\")\n",
    "for i in range(len(X_pred)):\n",
    "    print(\"{} \\t {}\".format(y_actual[i],y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = sess.run(accuracy, feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the test set is 98.9%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy on the test set is {}%\".format('{0:.4}'.format(acc_test*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A much better performance is achieved by stacking an additional layer of convolution and pooling<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close() #Close the tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
